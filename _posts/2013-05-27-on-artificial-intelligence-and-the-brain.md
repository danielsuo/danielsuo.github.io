---
layout: post
title: On artificial intelligence and the brain
categories: [beliefs]
published: false
---

I wouldn't read into the Wired hype too much. I would say the AI community agrees on a much less exciting set of statements:

1) Recent approaches (i.e., 5-10 years ago) to problems that benefit from 'learning' used paradigms not well-suited to AI (e.g., searching massive solution spaces, trying to prune exponentially growing trees)
2) We can draw inspiration from how the brain might generally work based on simplistic observations (e.g., ordered memory, hierarchical pattern recognition)

In fact, I might go as far as to use the bird:plane::brain:computer analogy. We take important ideas from nature, but it takes time to calibrate out the mimicry that doesn't work very well. It's not immediately obvious that the plane shouldn't have flapping wings! Once we figured out lift, we benefited massively and we can now fly longer and further than any bird. Of course, it's still hard to do VTOL, so the analogy to brain:computer holds reasonably well.

Either way, I agree with the Cindy Crawford comment. The issue of human biases--from the completely erroneous to the mild association--is sort of swept under the rug because, well, computers that can think like brains are just the shit. And never mind the fact that electronic brains would have much greater plasticity (always assumed for better, but rarely considered for worse).

There certainly are folks in the AI community who want to *replicate* the brain, but for now, it seems that many more are just interested in tackling challenging problems with whatever approach that might work. For recognition problems, hierarchical / recursive approaches are very promising (think OCR or speech recognition) because it just gets really tiring to write all these procedural rules for what cats look like.

But things get more interesting when you move beyond software-level solutions to the hardware layer. For example, neuromorphic chips promise both reliable analog signaling and massively parallel computation. The published approaches look silly now (borderline ridiculous, actually), but it's an important area to research because...math says so: exaflops burn a lot of calories and aren't even sufficient after a few iterations.

I think AI and theoretical neuroscience/learning algorithms are super cool, but I had to silent-LOL at this sentence:

"The rub is that we still donâ€™t completely understand how the brain works, but scientists are pushing forward in this as well." 
The phrase "completely understand" should be replaced with "have any fucking clue." And the phrase "scientists are pushing forward in this as well" should be replaced with "most scientists are struggling against NIH budget cuts and still trying to figure out when 'big data' became something not to cough uncomfortably at."

There's no question that this kind of learning algorithm has tons of important applications, but I don't get the claim that it's somehow more biomimetic. Anyone who watches a young child is struck by just how much the brain "learns" based on an extremely small number of examples. It's an immense power that we don't understand at the biological or theoretical levels, and as with the incredible recognition power of the immune system, it comes with serious consequences: a brain can "learn" that bunnies are terrifying, or that gambling is a great way to make money, despite overwhelming evidence to the contrary. There's this unspoken sentiment that the brain's power stems from its plasticity, without much appreciation for how inefficient and ballistic that plasticity can be. Surely there will soon be a computer that can recognize faces as well as any person, but will that computer see the girl down the hall with a mole and be forcefully reminded of Cindy Crawford, who was everywhere when it was being programmed?

This is more of a neuroscience than a computer science rant--but I think many researchers interested in the brain completely miss the most important question in neuroscience: what problems did *a* brain evolve to solve? I say "a brain" because different animals evolved very different brains to do very different things, yet the aspects of brain structure that biologists study and computer scientists model are remarkably similar across species--at least from our low-resolution and primitive point of view. There's no reason to think a biomimetic computer would be better than a rationally designed one, since cultural evolution works so much faster than genetic evolution--but I think we're missing most of the underlying principles for how brains do what they do. I hope neuroscientists and computer scientists alike stick to the most important principle of science: the test of a new theory is experiment, and not whether it sounds fancy enough to get funded.

Also the ferret paper the article links to is a classic, but its use there is kind of misleading. It's not like the ferrets see with anything approaching normal vision, and the remapping of cortical space within a sensory modality is much more facile than mapping to a new modality.