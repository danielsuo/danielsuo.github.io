<!doctype html>
<html>
  
  <head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<title>Daniel Suo | Scientific progress goes 'boink'</title>

<link rel="stylesheet" href="/assets/css/styles.css">
<link rel="stylesheet" href="/assets/css/pygment_trac.css">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<link rel="shortcut icon" href="/assets/img/profile.jpg" />

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<!--[if lt IE 9]>
<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

  <body id='beliefs'>
    
    <div class='wrapper'>
      
      <header>
    <h1>Daniel Suo</h1>
    <p>Scientific progress goes 'boink'</p>
    
    <ul>
    	<li><a href="/" id="home">home</a></li>
    	<li><a href="/archive" id="archive">archive</a></li>
        <li><a href="/projects" id="reading">projects</a></li>
    </ul>

    <div class="cb-tip-button" data-content-location="" data-href="//www.coinbase.com/tip_buttons/show_tip" data-to-user-id="515097e7e82052a271000007"></div>
    <script>!function(d,s,id) {var js,cjs=d.getElementsByTagName(s)[0],e=d.getElementById(id);if(e){return;}js=d.createElement(s);js.id=id;js.src="https://www.coinbase.com/assets/tips.js";cjs.parentNode.insertBefore(js,cjs);}(document, 'script', 'coinbase-tips');</script>
</header>

      <section>

        <div id='container'>
          
  <h2><a href="/beliefs/2013/06/14/on-a-technology-thesis.html">On a technology thesis</a></h2>
  <p class="author">
    <span class="date">14 June 2013</span>
  </p>
  <div class="content">
    <p>Thought this would be an interesting exercise, but the email got so long over the last hour that I have to have, like, a table of contents. My fear is that such a long email will cockblock a fruitful discussion (man, I don’t have time for this shit), but the hope is that this topic is interesting enough to overcome that.</p>

<p>Section 1: Introductions – lots of names floating around on this email
Section 2: Thesis? Da fuq? – what do you think the future looks like? what would be the biggest changes to human behavior as a result?</p>

<hr />

<p>Section 1: Introductions
This is a topic that I thought would benefit from folks not yet on LAC discussing – in particular, a few people Kane roped together for a Sunday afternoon meetup to talk tech. Didn’t add all the new folks to LAC directly because growing lists inorganically feels like just that; inorganic. My general rule of thumb is that if most people have met in person, then it’s all good. I think we’re almost there.</p>

<p>New folks cc’d: James Knight (Romotive -&gt; Google, engineer), Josh Vekhter (Mathematician -&gt; ZocDoc, engineer), Kevin Kwok (Greylock, VC), and David Luan (Thiel fellow -&gt; founder of computer vision startup) joined us for an afternoon talking shop. Peter Boyce needs no introduction.</p>

<p>Leather Apron Club (LAC): a wannabe intellectual descendant of Ben Franklin’s Junto. You’ve got (from this past Sunday) me, Kane, Lisa, Yoni, Allen, and also Dennis Tang (GQ editor), Winston Yan (MD/Phd at Harvard), Tina Zou (Goldman banker, soon to be data scientist), Kevin Lee (Hudson River Trading, continuing to be Hudson River Trading), and Benny Zhu (Founder of financial data analytics company).</p>

<p>Phew. That was way longer than I intended, but for sake of positively growing a small group, hope it was worth it.</p>

<hr />

<p>Section 2: Defining a thesis
Quick background: Michael got a meeting with Fred Wilson of Union Square Ventures, and I started wondering how one might impress a guy like Fred Wilson. One answer – have a thesis on what will happen next in the world of technology – led to a bigger question: what would our thesis be and, almost the more difficult question, how would we even find it?</p>

<p>For example, when FW started USV, his thesis was effectively two-fold: 1) web services, or the application layer, will inject technology into the lives of the masses and 2) NYC will be a mecca for start-up technology because media, telecom, and finance would be the next areas gobbled up by tech.</p>

<p>This thesis seems trivial now, but it wasn’t in 2004. In fact, it flatly contradicted mainstream thinking and it’s been the intellectual underpinning for USV’s success (that and not being dicks).</p>

<p>So let’s try to tackle the questions in reverse. First, how would we even find a thesis? I imagine it would be a triangulation between a) the past and b) imaginations of the future. The past informs us of general principles by which value is determined and created, and imaginations of the future helps us Wayne Gretsky.</p>

<p>To me, value falls into time, status, or pleasure (status being big and different enough in nature from pleasure that I break it out) and it is created by either human or technological means (I lump pack animals in with “technology”). Historically, mass wealth was created by enslaving (Ford and MSFT count), claiming, or trading and often a combination of the three. Today, we effectively do the same with technology: we buy technology, claim digital land and mind share, and trade the results.</p>

<p>Given all that, what could be massively valuable in the future? Put another way, what would our thesis be? A first order estimate might be [insert trend already happening in certain industries, e.g., web services] will come to dominate [insert industry not yet affected]. But let’s bump up to second order. We’re hearing a lot about ‘the internet of things’, ‘wearable computing’, ‘3Dification’ (both UX and atoms &lt;-&gt; bits) and augmented reality, which are all really ways of breaking computing out of their traditional domains (i.e., computer devices) to help users fuse technology more naturally with the world around them. In other words, as technology advances, it becomes less apparent to the end user.</p>

<p>This is probably far enough for a VC’s practical purposes. If your head’s too far in the clouds, you’ll pretty soon find it up your own ass.</p>

<p>For t3h shits, what if we think 3rd order: if software will eat the world, what will eat software? My sense is that new hardware paradigms will birth new ways of conceiving of and architecting software. If you’ve read Innovator’s Dilemma (summary here), you might recognize this as a kind of meta disruption (not the buzzword disruption here, but as originally defined by Christensen). As software becomes more and more attractive from a business perspective (insane margins, massive scalability, insanely low capital outlay), folks trend towards it at the expense of lower-margin, smaller markets. But these are exactly the places where innovation happens and how large established companies get eaten up.</p>

<p>So, I’ll rephrase this as short-, medium-, and long-term theses:</p>

<p>Short-term (next 5 years): Software will continue eating the world
Medium-term (next 10 years): Software will be abstracted away in much the same way hardware is being abstracted away today–all about the UX
Long-term (next ?? years?): Hardware will eat software (e.g., your brain is simultaneously hardware and software)</p>

<p>Before this afternoon, I’d never really thought about a “thesis” and certainly don’t have any convictions on what will happen in the future of technology. I’m just spewing shit here, so very curious to hear what you all think about what lies ahead, especially if you have something more specific than these absurdly broad strokes.</p>

<hr />
<p>On that note, a brain fart: we’ve been biased (so far, anyway) to the leading edge of technology.</p>

<p>​I sort of wrote off the expansion of current trends to wider industries / people as first order, but that’s probably short-sighted of me.</p>

<p>​I would only need to point to emergent properties that might arise as more people and industries catch up to where leaders are today. One cell whatevs, but a few trillion?</p>

<p>​I like the wave metaphor–disruption happens both from fully processing a wave (long-form disruption?) and from new waves.</p>

  </div>

  <h2><a href="/beliefs/2013/06/13/on-innovation-at-large-companies.html">On innovation at large companies</a></h2>
  <p class="author">
    <span class="date">13 June 2013</span>
  </p>
  <div class="content">
    <p>Yeah–when I was at McKinsey, I spent a lot of time reading about innovation in context of large business and there are just an overwhelming number of reasons why they cannot (and in this case should not) be true innovators.</p>

<p>However, I still disagree with this guy’s advice because I see it as short-sighted. First, companies who adopt this attitude of buying innovation almost never stay at the forefront of observing said innovation (i.e., even if they could buy it, they don’t see it). Second, companies with vast resources are exactly the ones who could be bearing the risk of trying (and failing), but instead, institutional pressure prevents them from even trying. If you try to innovate and fail, your job is on the line, but as the old saying goes, “no one ever got fired for buying IBM” (i.e., taking the conservative path).</p>

<p>I admire companies like Google and Intel because they don’t mind investing large amounts of capital on unknown payoffs from R&amp;D. However, even they fall into a particular type of innovation trap articulated by Professor Christensen at HBS (innovator’s dilemma) – as companies mature, they tend towards greener pastures (e.g., higher-margin higher-end products), but in doing so, they leave themselves vulnerable to scrappy upstarts who don’t mind the brown grass and eventually eat the big companies from behind.</p>

<p>This is probably too much information without enough context, so I’ll stop here. Simply put: large companies don’t “innovate” as much as they should, but for very understandable, if not excusable, reasons.</p>

<p>Also, it goes without saying that his logic reduces to no innovation. Why should <em>anyone</em> bother innovating? Especially if my entire life’s savings and years of my efforts as an entrepreneur are going into something that might fail.</p>

<p>One last thought: Lisa is working on an internal project for McKinsey reviewing survey information from CEOs and other business leaders regarding long-term planning. One of the main criticisms and complaints of and from business people today is that short-term thinking persists. For example, we’ll do everything we can to make this quarter’s sales look good, even to the detriment of future quarters and we certainly wouldn’t invest large amounts today because a) that’s money out today and b) uncertain gains tomorrow.</p>

<p>McKinsey’s chief has been pushing this concept ‘Long-Term Capitalism’ for the past year or two, but I think his message is both flawed and naive. He raises the well-known problems I described above, but offers solutions that are fairly trivial (mostly of the flavor, X group of influential people must champion and lead the charge). These solutions simply don’t address the pressures that these people face. As a board member of a public company, I am paid several hundred K a year to go to a few board meetings and if I rock the boat, share prices might go down. If they go down, not only would I lose my seat, I’d also likely lose status and future board positions as well. As an institutional investor (think Vanguard), if I can’t generate good returns each quarter, people will move money from my fund to someone else’s–and I will get paid significantly less!</p>

<p>The one example of a great company that is both innovating and investing for the long term is Amazon. I completely forgot about them earlier, but a conversation with Lisa just now reminded me. For virtually their entire existence, they’ve told their shareholders that they will reinvest all profit back into the business (i.e., no profit left to distribute to shareholders). The only reason they can get away with this and still have such a well-performing valuation (as indicated by stock price) is because they have proven time and again that they make very, very good use of that capital. They are “taking over the world” and generating better returns on that capital than the vast majority of investors could do otherwise, so they don’t complain!</p>

<p>In a word, they have earned shareholder trust to invest for the long-term. This is the key component missing in all of these initiatives and speeches and everything else. I trust that you will spend my money better than I could spend it myself. And just like any other form of trust, it must be earned and it will never be easy!</p>

  </div>

  <h2><a href="/beliefs/2013/06/06/on-a-crowdsourcing-model.html">On a crowdsourcing model</a></h2>
  <p class="author">
    <span class="date">6 June 2013</span>
  </p>
  <div class="content">
    <p>Anyway, a completely unsolicited thought for consumer crowdsourcing (sounds like you’re thinking about enterprise): there’s an intriguing co-op grocery store in Park Slope, Brooklyn (a land of yuppies / hipsters…yupsters?). They have very cheap, extremely high quality food because in order to shop there, you must work for X hours / month in the store. They have massive throughput because competitors can’t come close on value (ignoring, for the moment, other unfair advantages e.g., the community feel, possibly less profit-motivated owners).</p>

<p>To link back to crowdsourcing, you effectively make demand for and supply of labor the same. This likely doesn’t work for many problems (i.e., is Park Slope replicable), but may have applications that an otherwise strictly better duolingo / recaptcha model (supply and demand demand and supply each other) can’t address. Perhaps processing high-demand data: to consume processed data (e.g., deduplicated tweets), you must process some data or pay some money. Mathematically, I think this scales; each piece of data needs to get processed a few times to ensure accuracy, but can be consumed by a massive number of people.</p>

  </div>

  <h2><a href="/beliefs/2013/06/02/on-product-strategy-model.html">On product -> strategy -> model</a></h2>
  <p class="author">
    <span class="date">2 June 2013</span>
  </p>
  <div class="content">
    <p>http://www.avc.com/a_vc/2013/06/product-strategy-business-model.html?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+AVc+%28A+VC%29</p>

<p>Great article. Sounds like some of the better stuff from amongst the business garbage I read.</p>

<p>Using his paradigm, I’d say, we’re still in the product phase and just beginning to articulate strategy (e.g., making data collection free so that people have what they need to use our great tools). I don’t think it’s bad to keep potential business models in mind (as we’re doing), as long as we’re not beholden to any one in particular.</p>

<p>One slight criticism of the note: FW doesn’t define strategy and assumes folks just know what the word means. I would argue that most people do not, in fact, know what it means and even if “they do”, it means different things to different people. For example, one could argue that strategy is really a spectrum across different time horizons. Strategy for getting the next sale would be on the short end and might be called a tactic. Strategy for bringing product to market might be a “strategy”. And strategy for the next ten years might be called vision.</p>

<p>So let’s define strategy, for the moment, as getting from A to B over some time horizon (say, the next year). Then what FW is really saying is that before we lock down a business model, we must determine B and our path to B, and that <em>good</em> strategy finds some B where we add tremendous value / is very difficult for others to reach. When and only when we deliver massive, defensible value (i.e., the result of smart strategy), can we begin to truly think about monetizing the value created (i.e., the business model).</p>

<p>Put very simply: first figure out if people want it, then make them need it, then charge for it in the most natural and (hopefully) profitable way.</p>

  </div>

  <h2><a href="/beliefs/2013/06/02/on-analog-computing.html">On analog computing</a></h2>
  <p class="author">
    <span class="date">2 June 2013</span>
  </p>
  <div class="content">
    <p>Today, there is:
1. No general analog computing - if I want to modify an analog signal, I typically need specialized hardware. In the digital world, I can change bits however I want very quickly</p>

<ol>
  <li>No scalable analog computing - it is easy to have one analog source sending to another analog output. It is very challenging to scale the number of sources and outputs to the scale where computing becomes interesting
a) Transmitting analog signal requires hard wiring between source and output, which becomes untenable very quickly (number of connections possible between n nodes is on the order of n^2)
b) Even if there were some media by which arbitrary sources and outputs can connect, it would be very challenging for an output to sort through all the noise from other sources and without significant source decay</li>
</ol>

<p>Solving these two problems give rise to a new class of computing hardware that would dramatically change how we solve a number of problems today via:</p>

<ol>
  <li>
    <p>Rapid data transmission / processing: today, we simulate an analog signal with a some number of bits because we cannot reliably measure an analog signal at scale. To demonstrate the power of analog computation, water will find the fastest path down a mountain rapidly, but this would freeze even the most powerful computers</p>
  </li>
  <li>
    <p>Arbitrary formation of new, directly linked connections: right now, we facilitate the connection of two computers over a network via centralized hardware – a bottleneck – or, in less common cases, via directly wired connections, which are expensive to implement at scale</p>
  </li>
  <li>
    <p>Energy efficiency: computing resources only work when they receive some signals to process and are otherwise off, instead of being always on</p>
  </li>
</ol>

<p>The reason I’m excited by this is because it seems to be a very general use case for analog signaling. A very natural extension of this idea is analog inputs (like our sense of touch, for instance), which today would first be converted to a digital signal before being processed. True analog input to true analog computing would not require such a translation.</p>

<p>Today, we have CPUs that do logic and arithmetic very well and GPUs (graphics processing units) that do parallel logic and arithmetic very well. Analog computers (APUs?) would sit alongside existing hardware today to be used for specific types of problems in much the same way as CPUs and GPUs are used for very specific tasks today.</p>

  </div>


<!-- Pagination links -->

  <div class="pagination">
    
      <span><a href="/beliefs//beliefs/index.html" class="previous">Previous</a></span>
    

    <span class="page_number ">Page: 2 of 3</span>

    
      <span><a href="/beliefs//page3" class="next">Next</a></span>
    
  </div>


        </div>

      </section>

      <footer>
  <social>
	<a href="http://facebook.com/danielsuo"><img src="/assets/img/facebook.png"></a>
	<a href="http://twitter.com/danielsuo"><img src="/assets/img/twitter.png"></a>
  <a href="http://www.linkedin.com/in/danielsuo"><img src="/assets/img/linkedin.png"></a>
  <a href="https://github.com/danielsuo"><img src="/assets/img/github.png"></a> 
  <a href="/feed.xml"><img src="/assets/img/rss.png"></a> 
</social>
  <br><br>
  <small>Complain <a href="mailto:dsuo@post.harvard.edu">here</a>.</small>
  <small><a href="/pubkey.txt">Securely</a>.</small>
</footer>
      
    </div>

    <script src='/assets/js/scale.fix.js'></script>
    <script type="text/javascript">
var gaJsHost = (('https:' == document.location.protocol) ? 'https://ssl.' : 'http://www.');
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
varpagetracker:_gat._getTracker(UA-37351701-1)
}


  </body>
</html>